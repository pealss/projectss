{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b8f21a-5ab8-41cb-baca-b06d3366eb30",
   "metadata": {},
   "source": [
    "## Text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b6033c-af52-4e54-be41-431ca3a2a6ae",
   "metadata": {},
   "source": [
    "Writing texts will produce errors, some of these errors are quite simple. Typos, word duplication and punctuation. Typos can be mainly fixed by online dictionaries but for word duplication and punctuation detection special programs are needed. We want to implement a simple word duplication with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6356023d-56af-494a-949f-44be2441e57e",
   "metadata": {},
   "source": [
    "Let's assume these kind of errors:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889e163a-3a87-4b1c-8d5e-a640432c6758",
   "metadata": {},
   "source": [
    "``` \n",
    "... we often often make ...\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```\n",
    "... here. this ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b14cc-10db-4aa6-9406-c719118f3fd9",
   "metadata": {},
   "source": [
    "In `data/faulty_text.txt` we have added a few errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b6d65-675a-47c4-b57f-eec31f16ade3",
   "metadata": {},
   "source": [
    "**Your task:**\n",
    "\n",
    "Write a python script `text_analysis.py` in which you write a function `detect_errors` with takes a filename as an argument and uses the `logging`-module for indicate the `errors` (`logging.error`). Test your function with `data/faulty_text.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca398271-05e2-40d6-b79f-f9278bc79e69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Here', 'some', 'text', 'with', 'double', 'double', 'words', 'words', 'It', 'also', 'contains', 'puctuation', '']\n"
     ]
    }
   ],
   "source": [
    "# example to split a string into words taking into account\n",
    "# (removing) punctuation.\n",
    "# For time reasons, we will not treat 'regular expressions' in class\n",
    "# but you should look them up yourself! You should know them from\n",
    "# Linux already.\n",
    "\n",
    "import re # module to handle regular expressions in a Python program\n",
    "\n",
    "s = \"Here some text with double (double!) words words. It also contains puctuation!\"\n",
    "\n",
    "# split s into its words without the punctuation marks; note that\n",
    "# you might end up with empty strings in the word list!\n",
    "words = re.split('\\W+', s.rstrip())\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baafbc24-b437-4627-9674-484cbf138925",
   "metadata": {},
   "source": [
    " * take also into account that you check for duplication after switching to a new line\n",
    "   ```\n",
    "   ... test\n",
    "   \n",
    "   test ...\n",
    "   ```\n",
    "   Also do this for the punctuation tests!\n",
    " * keep also track of line numbers and word positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50bef04-0a97-4b15-a913-6c498ce47d15",
   "metadata": {},
   "source": [
    "My program gave these results:\n",
    "\n",
    "```\n",
    "ERROR:root:line 1 word #6: often\n",
    "ERROR:root:line 2 word #6: here\n",
    "ERROR:root:line 2 word #7: this\n",
    "ERROR:root:lines 5+6: words\n",
    "ERROR:root:lines 8+10: test\n",
    "ERROR:root:line 11 word #1: this\n",
    "```\n",
    "\n",
    " * it is not necessary to reproduce the results in detail, but you should address the same errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e417a813-ee6b-4425-a3aa-28938532fbd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:same word in line 1 word 6+7: often\n",
      "ERROR:root:same word in line 2 word 6+7: here\n",
      "ERROR:root:same word in line 5+6 word 5+1: words\n",
      "ERROR:root:same word in line 8+10 word 3+1: test\n",
      "ERROR:root:punctuation error in line 2 word 8: this\n",
      "ERROR:root:punctuation error in line 11 word 1: this\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import re\n",
    "\n",
    "# Configure the logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "def detect_errors(filename):\n",
    "    words_no_punc = []  # list without punctuation\n",
    "    words_with_punc = []  # list with punctuation\n",
    "    temp, index_j, index_i = '', 0, 0  # initialize variables for tracking\n",
    "\n",
    "    # opening the text file and reading the lines separately (with error handling)\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            data = f.read().splitlines()\n",
    "    except IOError:\n",
    "        print('Error reading the file!')\n",
    "        return\n",
    "\n",
    "    # split lines into words and add to the list\n",
    "    for line in data:\n",
    "        words_no_punc.append(re.split('\\W+', line.rstrip()))  # remove punctuation and split words\n",
    "        words_with_punc.append(line.split())  # split words including punctuation\n",
    "\n",
    "    # loop through all the words to check for repeated words\n",
    "    for i in range(len(words_no_punc)):\n",
    "        for j in range(len(words_no_punc[i])):\n",
    "            # check if this isn't the first line\n",
    "            if i != 0:\n",
    "                # check if the current word matches the previous word with some specific conditions\n",
    "                if (words_no_punc[i][j] == temp) and (temp != ''):\n",
    "                    if j == 0:\n",
    "                        logging.error(f\"same word in line {index_i+1}+{i+1} word {index_j+1}+{j+1}: {temp}\")  # log the error\n",
    "                    else:\n",
    "                        logging.error(f\"same word in line {i+1} word {index_j+1}+{j+1}: {temp}\")  # log the error\n",
    "            else:\n",
    "                if j != 0:\n",
    "                    if (words_no_punc[i][j] == temp) and (temp != ''):\n",
    "                        logging.error(f\"same word in line {i+1} word {index_j+1}+{j+1}: {temp}\")  # log the error\n",
    "            # save the last checked word for comparison in the next iteration\n",
    "            if words_no_punc[i][j] != \"\":\n",
    "                temp, index_j, index_i = words_no_punc[i][j], j, i\n",
    "\n",
    "    # loop through the words with punctuation to find punctuation errors\n",
    "    dot = False\n",
    "    for i in range(len(words_with_punc)):\n",
    "        for j in range(len(words_with_punc[i])):\n",
    "            # check if the previous word had a dot and the current word is lowercase\n",
    "            if (dot is True) and (words_with_punc[i][j].islower()):\n",
    "                logging.error(f\"punctuation error in line {i+1} word {j+1}: {words_with_punc[i][j]}\")\n",
    "            # check if the current word contains a dot\n",
    "            if \".\" in words_with_punc[i][j]:\n",
    "                dot = True\n",
    "            # reset dot flag if the current word does not contain a dot\n",
    "            elif words_with_punc[i][j] != \"\":\n",
    "                dot = False\n",
    "\n",
    "detect_errors(\"data/faulty_text.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaccb025-d076-4400-bea2-ff72a7823251",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af952fcf-eacf-4e97-8461-debf8a75a352",
   "metadata": {},
   "source": [
    "## Language detection of text files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570ca6b1-a5f9-4792-bc17-776b96bc620b",
   "metadata": {},
   "source": [
    "Language detection of written texts can be very complex, but we want to implement an easy to understand solution. The analysis is based on letter frequency (see this [Wikipedia article](https://en.wikipedia.org/wiki/Letter_frequency)). So for an unknown text the letter frequency can be calculated and compared with some predefined statistics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ccb00c-a17c-4901-b76f-a15ca0eb1e18",
   "metadata": {},
   "source": [
    "```Python\n",
    "wikipedia_stats_english = { 'e': 0.1270, 't': 0.09056, 'a': 0.08167, 'o': 0.07507, 'l': 0.06966, 'n' : 0.06749 }\n",
    "wikipedia_stats_german  = { 'e': 0.1639, 'n': 0.0978, 's': 0.0727, 'r' : 0.0700, 'i': 0.0655, 'a': 0.0651 } \n",
    "wikipedia_stats_italian = { 'e': 0.1179, 'a': 0.1174, 'i': 0.1128, 'o' : 0.0983, 'n': 0.0688, 'l': 0.0651 } \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "I simply used these three languages, since other europeen languages can be simply identified by some special characters!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3099f-f8b4-4817-9676-69f7a9ced355",
   "metadata": {},
   "source": [
    "In the folder `texts` we have a few text files for which you should decide which language is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38128996-a2be-4a52-ae18-827bb11cfaf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test01.txt  test03.txt\ttest05.txt  test07.txt\n",
      "test02.txt  test04.txt\ttest06.txt\n"
     ]
    }
   ],
   "source": [
    "!ls texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbacd67f-2f72-4da8-a45a-572e938e5112",
   "metadata": {},
   "source": [
    "### Read the text file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1466d7cd-440c-411c-aeaa-a3db237d761f",
   "metadata": {},
   "source": [
    "Start with the text-file `test01.txt` as a development example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745bb250-15ed-488f-beb6-207b4b80f98a",
   "metadata": {},
   "source": [
    "\n",
    "**Your task:**\n",
    "\n",
    "Define a function `read_file_to_letters` in the modul `letters` which takes a filename as an argument. It should return the letter frequency  of the data with the given filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97433618-e5bc-4369-b256-77e09e8654cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter frequencies in the text:\n",
      "a: 0.0645\n",
      "b: 0.0102\n",
      "c: 0.0204\n",
      "d: 0.0238\n",
      "e: 0.1210\n",
      "f: 0.0249\n",
      "g: 0.0271\n",
      "h: 0.0577\n",
      "i: 0.0905\n",
      "j: 0.0000\n",
      "k: 0.0045\n",
      "l: 0.0509\n",
      "m: 0.0339\n",
      "n: 0.0701\n",
      "o: 0.0701\n",
      "p: 0.0283\n",
      "q: 0.0023\n",
      "r: 0.0633\n",
      "s: 0.0600\n",
      "t: 0.0860\n",
      "u: 0.0294\n",
      "v: 0.0147\n",
      "w: 0.0192\n",
      "x: 0.0000\n",
      "y: 0.0249\n",
      "z: 0.0023\n"
     ]
    }
   ],
   "source": [
    "import letters\n",
    "\n",
    "filename = 'texts/test01.txt'\n",
    "letter_frequencies = letters.read_file_to_letters(filename)\n",
    "if letter_frequencies:\n",
    "    print(\"Letter frequencies in the text:\")\n",
    "    for letter, freq in letter_frequencies.items():\n",
    "        print(f\"{letter}: {freq:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141042b-b400-48e8-91aa-978ec6f3bab7",
   "metadata": {},
   "source": [
    "### 3.3 Compare the languages (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfc4e51-9ad6-427b-9991-3157fc669e47",
   "metadata": {},
   "source": [
    "The next task is to compare your letter frequency with some predefined statistics and decide how well your data fits. You can simply check for each given letter the distance `d` from your value with the given value. The value `1-d` will then give you a fit for an individual letter. For the sequence of letters the minimum of all individual `1-d` values will then describe how good a language will fit to the data. The larger this value will be, so higher is the probability that the letter frequency fits the predefined data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f5aa7b-05f4-4b1c-8d25-7b5b4f7b5a29",
   "metadata": {},
   "source": [
    "**Your task:**\n",
    "\n",
    "Define a function `test_language` in the module `letters` which takes the your letter frequency and a predefined statistic as arguments and returns the minimum value `1-d` for all individual letters in the predefined statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa6578e-e16c-4ee9-a875-475021b5bf9b",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    " * use __only__ the letters defined in the predefined statistics for the analysis\n",
    " * call the function from the main script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b26f90-bab7-4637-a7c3-92d387757caf",
   "metadata": {},
   "source": [
    "### Decision of languages "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0423efe9-604e-461d-9100-a1ad9ff08550",
   "metadata": {},
   "source": [
    "Based on the previous tasks, we need now to decide which language fits best. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74debb8-717d-4b4f-b368-4d979af42602",
   "metadata": {},
   "source": [
    "**Your task:**\n",
    "\n",
    "Define a function `decide_language` in the module `letters` which takes your letter frequency and returns a language name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ade19a-662c-4e0f-aa92-5a9dee5517cb",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    " * call the function from the main script\n",
    " * `test_language` is not needed any more for your main script, remove the `import` of this function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2770d05-327d-4790-93cc-9e7611ea5548",
   "metadata": {},
   "source": [
    "### Batch-check "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddfc785-20b9-40b6-9199-c91e023b378b",
   "metadata": {},
   "source": [
    "**Your task:**\n",
    "\n",
    "Check all given files in `texts/` for the used languges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb010cd-44de-483a-acf4-f80377519301",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['texts/test04.txt', 'texts/test05.txt', 'texts/test01.txt', 'texts/test02.txt', 'texts/test03.txt', 'texts/test07.txt', 'texts/test06.txt']\n"
     ]
    }
   ],
   "source": [
    "# The glob-module allows you to use Linux style\n",
    "# pathname expansion\n",
    "import glob\n",
    "\n",
    "# generate a list of files matching the Unix-pattern\n",
    "# texts/*.txt. \n",
    "datapath = \"texts\"\n",
    "filelist = glob.glob(f\"{datapath}/*.txt\")\n",
    "\n",
    "# print the resulst\n",
    "print(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bab09e3-35e0-4b0a-80ed-6b72cf12d257",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter frequencies in the text:\n",
      "a: 0.0645\n",
      "b: 0.0102\n",
      "c: 0.0204\n",
      "d: 0.0238\n",
      "e: 0.1210\n",
      "f: 0.0249\n",
      "g: 0.0271\n",
      "h: 0.0577\n",
      "i: 0.0905\n",
      "j: 0.0000\n",
      "k: 0.0045\n",
      "l: 0.0509\n",
      "m: 0.0339\n",
      "n: 0.0701\n",
      "o: 0.0701\n",
      "p: 0.0283\n",
      "q: 0.0023\n",
      "r: 0.0633\n",
      "s: 0.0600\n",
      "t: 0.0860\n",
      "u: 0.0294\n",
      "v: 0.0147\n",
      "w: 0.0192\n",
      "x: 0.0000\n",
      "y: 0.0249\n",
      "z: 0.0023\n",
      "\n",
      "Detected Language: English\n",
      "\n",
      "filename: texts/test01.txt\n",
      "Detected Language: English\n",
      "\n",
      "filename: texts/test02.txt\n",
      "Detected Language: German\n",
      "\n",
      "filename: texts/test03.txt\n",
      "Detected Language: German\n",
      "\n",
      "filename: texts/test04.txt\n",
      "Detected Language: Italian\n",
      "\n",
      "filename: texts/test05.txt\n",
      "Detected Language: Italian\n",
      "\n",
      "filename: texts/test06.txt\n",
      "Detected Language: English\n",
      "\n",
      "filename: texts/test07.txt\n",
      "Detected Language: English\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import letters\n",
    "\n",
    "def main():\n",
    "    # process a single file\n",
    "    filename = 'texts/test01.txt'\n",
    "    letter_frequencies = letters.read_file_to_letters(filename)\n",
    "    \n",
    "    if letter_frequencies:\n",
    "        print(\"Letter frequencies in the text:\")\n",
    "        for letter, freq in letter_frequencies.items():\n",
    "            print(f\"{letter}: {freq:.4f}\")\n",
    "        \n",
    "        detected_language = letters.decide_language(letter_frequencies)\n",
    "        print(f\"\\nDetected Language: {detected_language}\")\n",
    "\n",
    "    # process multiple files in a directory\n",
    "    datapath = \"texts\"\n",
    "    filelist = sorted(glob.glob(f\"{datapath}/*.txt\"))\n",
    "\n",
    "    for filename in filelist:\n",
    "        print(f\"\\nfilename: {filename}\")\n",
    "        letter_frequencies = letters.read_file_to_letters(filename)\n",
    "        \n",
    "        if letter_frequencies:\n",
    "            detected_language = letters.decide_language(letter_frequencies)\n",
    "            print(f\"Detected Language: {detected_language}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a51d5-a624-42cb-b107-acc7c8895e82",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
