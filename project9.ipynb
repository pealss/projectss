{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ada5f1a-8766-43cd-a112-1eff13f14120",
   "metadata": {
    "id": "8ada5f1a-8766-43cd-a112-1eff13f14120"
   },
   "source": [
    "We consider the one dimensional random walk. Starting from $x=0$ we walk in each time step a random step to the left or to the right with equal propability. We would like to estimate the quantities $\\langle d(t)\\rangle$ and $\\langle d(t)^2\\rangle$, where $d(t)$ is the distance from the origin at time $t$ after $N$ steps. With a simulation, we want to confirm known results from statistical mechanics:\n",
    "\n",
    "$$\n",
    "\\langle d(t)\\rangle = 0\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\langle d(t)^2\\rangle = N\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e10bfe2-88f6-4e27-be79-a93d9d2fded4",
   "metadata": {
    "id": "5e10bfe2-88f6-4e27-be79-a93d9d2fded4"
   },
   "source": [
    "<img src=\"figs/random_walk.png\" style=\"width: 300px;\" style=\"height: 200px;\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f5b8d-691a-4fae-bf1b-fd78d0d4b81a",
   "metadata": {
    "id": "473f5b8d-691a-4fae-bf1b-fd78d0d4b81a"
   },
   "source": [
    "**Task:**\n",
    "\n",
    "Obtain the desired quantities by simulating 1000 walkers and 200 time steps.\n",
    "\n",
    "**Hints:**\n",
    " * create a two-dimensional array with the walking stories of each worker in one direction and time in the other (see left side of the following figure)\n",
    " * the function `np.random.randint` allows you directly to create a 2D-array of random numbers)\n",
    " * use the created array to obtain another array containing $d(t)$ for each walker ($d(t)$ is just the cumulated sum of the individual steps; see right side of the following figure) (see `np.cumsum`)\n",
    " * obtain $\\langle d(t)\\rangle$ and $\\langle d(t)^2\\rangle$ and plot the quantities (applicate `np.mean` function along the stories-axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a566cd-b69e-428d-bccc-6bb304c7dce7",
   "metadata": {
    "id": "f1a566cd-b69e-428d-bccc-6bb304c7dce7"
   },
   "source": [
    "<img src=\"figs/random_walk_schema.png\" style=\"width: 600px;\" style=\"height: 300px;\">  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca5159-d8e8-46dd-8d9a-641f2cf5eb57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "74ca5159-d8e8-46dd-8d9a-641f2cf5eb57",
    "outputId": "20d37fe6-fa44-4ad0-ca22-f58278bffc59"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.5' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Berk/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_walkers = 1000\n",
    "\n",
    "num_steps = 200\n",
    "\n",
    "# simulate random steps\n",
    "steps = np.random.randint(0, 2, size=(num_walkers, num_steps)) * 2 - 1\n",
    "\n",
    "# compute the cumulative sum of steps for each walker\n",
    "distance = np.cumsum(steps, axis=1)\n",
    "\n",
    "# the mean of d(t) and d(t)^2\n",
    "mean_distance = np.mean(distance, axis=0)\n",
    "mean_distance_squared = np.mean(distance ** 2, axis=0)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(num_steps), mean_distance, label=r'$\\langle d(t) \\rangle$')\n",
    "plt.plot(range(num_steps), mean_distance_squared, label=r'$\\langle d(t)^2 \\rangle$')\n",
    "plt.xlabel('Time (t)')\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Average Distance from Origin')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8171b135-35bb-4ed3-9b51-404ceaf6f806",
   "metadata": {
    "id": "8171b135-35bb-4ed3-9b51-404ceaf6f806"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317a6ceb-c07e-4c40-a1ca-1b462edf05a4",
   "metadata": {
    "id": "317a6ceb-c07e-4c40-a1ca-1b462edf05a4"
   },
   "source": [
    "Despite of modern techniques in creating weather models to get a almost real prediction of a temperature, you can also think of a simple data mining approach. For many of the regions on earth we have weather stations which feed their data into a global database. These data can be fetched and analyzed. For the temperature prediction we simply have look inside the data to see if we can find a similar temperture trend, so if we can find the same temperature development, we can use the next temperature in the archive as a temperature prediction for the recent temperature. If you find may similar events in the database you can analyse these events. Creating a mean value for all these temperature is in quite naive but gives at least a good starting point for further analysis.\n",
    "\n",
    "However, this is a simple approach, which neglects all know effects on the temperature development, land scapes, air pressure, clouds, winds, solar power etc.\n",
    "\n",
    "I think this is a funny task and one can check how good is this prediction in comparison to the modern models. At least it will take less cpu ressources ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234e1d8-ffa1-4b50-9edd-40ba6854257c",
   "metadata": {
    "id": "1234e1d8-ffa1-4b50-9edd-40ba6854257c"
   },
   "source": [
    "### Weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9b394-6873-4456-82de-a200792af113",
   "metadata": {
    "id": "a0a9b394-6873-4456-82de-a200792af113"
   },
   "source": [
    "In the internet there is a package called `meteostat` (see https://dev.meteostat.net/python/) which offers you an access to global weather statistic data. If you know the weather station id, you can access different weather data time series. We focus on the hourly data from the weather station `Bonn-Roleber`. At the moment data can be downloaded from January 1st 2016 until now directly. These are the provided data:\n",
    "\n",
    "```\n",
    "                     temp  dwpt  rhum  prcp  snow   wdir  wspd  wpgt    pres   \n",
    "time                                                                           \n",
    "2016-01-01 00:00:00   4.7   2.1  83.0   0.0   NaN  180.0   9.7   NaN  1024.8  \\\n",
    "2016-01-01 01:00:00   4.3   2.0  85.0   0.0   NaN  200.0  13.3   NaN  1024.9   \n",
    "2016-01-01 02:00:00   4.7   2.1  83.0   0.0   NaN  190.0  11.5   NaN  1025.2   \n",
    "2016-01-01 03:00:00   4.6   2.3  85.0   0.0   NaN  190.0  11.9   NaN  1025.4   \n",
    "2016-01-01 04:00:00   5.0   2.9  86.0   0.0   NaN  200.0  17.6   NaN  1025.1   \n",
    "...                   ...   ...   ...   ...   ...    ...   ...   ...     ...   \n",
    "2023-05-04 06:00:00   9.4   4.6  72.0   0.0   NaN  105.0   9.3  16.7  1021.9   \n",
    "2023-05-04 07:00:00  11.5   5.1  65.0   0.0   NaN  110.0  11.1  18.5  1021.6   \n",
    "2023-05-04 08:00:00  13.9   5.8  58.0   0.0   NaN  117.0  13.0  22.2  1021.1   \n",
    "2023-05-04 09:00:00  15.9   6.1  52.0   0.0   NaN  123.0  14.8  25.9  1020.5   \n",
    "2023-05-04 10:00:00  18.0   5.9  45.0   0.0   NaN  127.0  16.7  27.8  1019.9   \n",
    "```\n",
    "\n",
    "For this task only the first column `temp` is interesting for as as well as the index `time`. The following code part, downloads the necessary data and can be used directly in your solution. Have a look at the code, so you can apply the solution to other quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc9c1024-d2e1-4f87-81f4-7e8951d82be2",
   "metadata": {
    "id": "cc9c1024-d2e1-4f87-81f4-7e8951d82be2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from meteostat import Hourly\n",
    "\n",
    "\n",
    "# Set time period, only from 2016 until 2023 is supported\n",
    "start = datetime(2016, 1, 1)\n",
    "end = datetime.now()\n",
    "\n",
    "# Get hourly data\n",
    "# id: 10519 = Bonn-Roleber\n",
    "\n",
    "data = Hourly('10519', start, end)\n",
    "data = data.normalize()    # be sure that all data is available,\n",
    "                           # gaps are filled\n",
    "data = data.fetch()\n",
    "\n",
    "\n",
    "# extract the times and the temperature data\n",
    "# and convert these to numpy arrays\n",
    "# the data is stored in pandas data frames,\n",
    "# which we not have in class so far!\n",
    "times = data.index.to_numpy()\n",
    "temps = data['temp'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d98d33-ad1b-49fb-8d47-853fe1edfc50",
   "metadata": {
    "id": "84d98d33-ad1b-49fb-8d47-853fe1edfc50"
   },
   "source": [
    "The arrays `times` and `temps` are now have necessary data stored in 1d-`numpy`-arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b2fb8-aede-4a31-87fe-655377219266",
   "metadata": {
    "id": "ac6b2fb8-aede-4a31-87fe-655377219266"
   },
   "source": [
    "The idea of a temperature prediction is to have a look in the data set if we can find $N$ consecutive values similar to the $N$ last recent values at a point $M$ insisde the archive data. The value $M+1$ follows the same $N$ values and is the *prediction* for the recent value. If more than one $M$ points are found, one can calculate the mean value for the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b23f14-9aa7-4421-ad91-b80b671dbab8",
   "metadata": {
    "id": "29b23f14-9aa7-4421-ad91-b80b671dbab8"
   },
   "source": [
    "**Task:**\n",
    "\n",
    "The task is to check the archive data for the occurrence of $N$ consecutive values. Evaluate the points $M$ in the archive data and calculate a predicted value for the temperature from the mean values. A direct search may be without any results, so perform all tests with an inaccuracy of `0.1` degrees. $N=3$ should work. If you have still no results, vary the accuracy and number of data points!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e9480-1f7e-4ac0-91ff-750a7d84c0e5",
   "metadata": {
    "id": "8f0e9480-1f7e-4ac0-91ff-750a7d84c0e5"
   },
   "source": [
    "**Hints:**\n",
    " * use the *rolling window* technique to split the temperature data array (see *Review questions*)\n",
    " * use `np.isclose` and `np.all` to check for the occurences of the test data and collapse the results to a linear array (see *Review questions*)\n",
    " * `np.nonzero(...)[0]` gives you an index array for the found data positions; you need to adjust the positions for the predicted values, how?\n",
    " * all the tasks can be written with `numpy` commands, use `slicing` and `masks`, loops are not allowed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c19ee99b-b7e4-4599-94be-2eb482f5398b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c19ee99b-b7e4-4599-94be-2eb482f5398b",
    "outputId": "3b75908d-c1ea-4e6d-9eac-3a4e7bbfb3d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.578947368421053"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your solution here please\n",
    "\n",
    "#first we create a rolling window which will stride along the temperature values in a form of a function.\n",
    "\n",
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window) #takes the shape of input array within the last dimension.\n",
    "    strides = a.strides + (a.strides[-1],)  #appends the stride of the last dimension of the input array to the strides tuple\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides) #gives the array after rolling window being applied.\n",
    "\n",
    "\n",
    "rolling_window(temps, 3)  #choosing a window of 3 data points as mentioned\n",
    "rolled_temps = rolling_window(temps, 3) #just giving a different name to the window function defined of size 3\n",
    "rolled_temps\n",
    "\n",
    "\n",
    "# Array to check for occurrence, specifically choosing the last array from the data.\n",
    "test = np.array([17.3, 16.9, 16.1])\n",
    "\n",
    "# Matching the test array with rolling window temperatures from the data with the tolerance of 0.1.\n",
    "matches = np.all(np.isclose(rolled_temps, test, atol=0.1),  axis = 1)\n",
    "\n",
    "np.nonzero(matches)[0] #giving nonzero values for the values which are within the tolerance\n",
    "matching_indices = np.nonzero(matches)[0]\n",
    "\n",
    "predicted_indices = matching_indices + 3  #gives the array of indices of the data points of interest\n",
    "predicted_indicess = predicted_indices[0:-1] #removes the last entry from our array\n",
    "\n",
    "predicted_temps = np.mean(temps[predicted_indicess]) #gives the mean of temperatures whose indices are calculated in the above array\n",
    "predicted_temps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d01e8d-40fe-4d10-9fab-2c1320ec4c54",
   "metadata": {
    "id": "f5d01e8d-40fe-4d10-9fab-2c1320ec4c54"
   },
   "source": [
    "### Epilogue\n",
    "\n",
    "If you try to use this approach for a temperature prediction for the whole day, it will obviously fail, since the program doesn't take into account the time of the test temperature nor the time of the found temperatures. So prediction for night temperatures are failing in any case. You can try to expand the solution to a daily temperature dataset. `meteostat` provides data with the function `Daily`, which then works similar as `Hourly`. The keyword for the temperature is `tmin` or `tmax` instead `temp`. So you can have a prediction for the min and max daily temperature. However, the search inside the database is much more difficult. One aspect is that the accuracy of the stored data is too high for a good search, I would convert all temperatures into integers and have a limit of 2° during the search to have enough data points for evaluation. Have a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "KhEcCjvdW-Bx",
   "metadata": {
    "id": "KhEcCjvdW-Bx"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.5' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Berk/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Generate synthetic data (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "x = np.random.normal(size=500)\n",
    "y = np.random.normal(size=500)\n",
    "z = np.random.normal(size=500)\n",
    "\n",
    "# Create figure and 3D subplot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel('Nonspectral Velocity')\n",
    "ax.set_ylabel('Log Stellar Mass Density')\n",
    "ax.set_zlabel('Redshift')\n",
    "\n",
    "# Scatter plot\n",
    "sc = ax.scatter(x, y, z, c=z, cmap='viridis', s=10, alpha=0.6)\n",
    "\n",
    "# Rotate the plot\n",
    "def update(frame):\n",
    "    ax.view_init(elev=10, azim=frame)\n",
    "\n",
    "# Animation\n",
    "ani = FuncAnimation(fig, update, frames=range(0, 360, 2), interval=50)\n",
    "\n",
    "# Save as GIF (requires ImageMagick or Pillow)\n",
    "ani.save('3d_rotation.gif', writer='pillow')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ab674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
